{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pwahTVssVjV8"
      },
      "source": [
        "# Little Women: the Python Step\n",
        "\n",
        "Congratulations on getting to this step in today's exercise! Take pride in being able to do some Bash!\n",
        "\n",
        "In the previous step we had Meg help us figure out the code for the zip file, whilst in the following step we are going to be asking the other three protagonists (Jo, Beth and Amy)* to help us with the code for `secret-2.zip`.\n",
        "\n",
        "\\* Perhaps it would be a good idea to remember this order ðŸ˜‰.\n",
        "\n",
        "## Assignment\n",
        "\n",
        "In order to figure out the secret that the Little Women are hiding from us, we will be using some Python libraries, specifically **NLTK** (Natural Language Toolkit), a powerful library for working with human language data.\n",
        "\n",
        "Similar to the previous exercise, we will be using NLTK to figure out the numbers required to unlock the second file!\n",
        "\n",
        "This notebook is 95% ready to give us the code, it is up to you to make the correct changes in order to obtain the right output.\n",
        "\n",
        "## Goal\n",
        "\n",
        "The objective of this notebook is **NOT** to make you a python expert, but to instead make you understand the correct synthax necessary to make Python work.\n",
        "\n",
        "Good luck!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DTdgNjCyqysK"
      },
      "source": [
        "## Step 1: Importing Files\n",
        "\n",
        "Modify the following cell to import the correct file (`LittleWomen.txt`) in this notebook. You should have pushed the file from your machine to the git repo -- see if you can import it here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RKTNFjUnVjgF"
      },
      "outputs": [],
      "source": [
        "with open(\"path/to/little/women.txt\") as file:\n",
        "  little_women = file.read()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LqYIGv3WRqjr"
      },
      "source": [
        "## Step 2: Importing Libraries\n",
        "\n",
        "The following libraries are what we need to make the notebook work. Notice how these are [commented out](https://flexiple.com/python/block-comment-python). Figure out how to uncomment them and import the libraries.\n",
        "\n",
        "<details>\n",
        "  <summary>Hint</summary>\n",
        "  Remove the `# ` from each line\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JTf8oSGPQCL_"
      },
      "outputs": [],
      "source": [
        "# import csv\n",
        "# import os\n",
        "# from collections import Counter\n",
        "# import nltk\n",
        "# nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZ3HFzatSjTB"
      },
      "source": [
        "##  Step 3: Token Transformation\n",
        "\n",
        "Transform the text file into a list of intemized tokens. This will allow *each word* to be searchable.\n",
        "\n",
        "Notice the `<insert correct string>`: what previously created string could be put in the parentheses?\n",
        "\n",
        "<details>\n",
        "  <summary>Hint</summary>\n",
        "  Look at the first code block.\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3LAn9NWLQYCm"
      },
      "outputs": [],
      "source": [
        "little_women_tokens = nltk.word_tokenize(<insert the correct string>)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tuCkCiFkSsO5"
      },
      "source": [
        "## Step 4: Formatting\n",
        "\n",
        "In order to make things easier to search, we first need to remove special characters, and save the remaining tokens to a list. Here we use a forloop and an `if` statement to iterate through the entire book and add to our list.\n",
        "\n",
        "<details>\n",
        "  <summary>Hint</summary>\n",
        "\n",
        "  Look at the code block below, and notice the `#` comment. In order to create a list you will require `[]`. The first line of the block should look like the following:\n",
        "  \n",
        "  ```\n",
        "  nocase_littlewomen = []\n",
        "  ```\n",
        "  \n",
        "  Do you know what the difference between `()` and `[]` is? [Here's a good resource to help you understand things further.](https://www.theserverside.com/blog/Coffee-Talk-Java-News-Stories-and-Opinions/Whats-the-difference-between-brackets-braces-and-parentheses)\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JhvIptEpSsXQ"
      },
      "outputs": [],
      "source": [
        "nocase_littlewomen = # [] or ()? <- choose between brackets and parentheses for creating a list\n",
        "for token in little_women_tokens:\n",
        "  if token.isalpha():\n",
        "    nocase_littlewomen.append(token)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3QIlL77VYNbp"
      },
      "source": [
        "## Step 5: Numerating\n",
        "\n",
        "This step Counts the number of instances of every word in the text file, and save it as a dictionary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cw0P6hB4VRPi"
      },
      "outputs": [],
      "source": [
        "word_count = Counter(word for word in nocase_littlewomen)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mg91PC7kZlRm"
      },
      "source": [
        "Optinoal: Print the dictionary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yybYGIzyWUhs"
      },
      "outputs": [],
      "source": [
        "print(word_count)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8oZI3vPYZolm"
      },
      "source": [
        "Optional: using the `print()` statement, we can see the amount of times a token (e.g., \"Jo\") is observed:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NUNk6ANnXbjW"
      },
      "outputs": [],
      "source": [
        "print(word_count[\"<word>\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ahu9oCVSZt5U"
      },
      "source": [
        "## Step 6: Asking the Right Questions\n",
        "\n",
        "Now that we have a complete list of filtered words, we can ask our main characters to help us out. Apart of Meg, here are 10 of the recurring characters from the book.\n",
        "\n",
        "Try to query the word_count dictionary for the following characters (remember to use quotations for strings):\n",
        "\n",
        "1. \"Kate\"\n",
        "2. \"Kitty\"\n",
        "3. \"Amy\"\n",
        "4. \"Marmee\"\n",
        "5. \"John\"\n",
        "6. \"Minnie\"\n",
        "7. \"Beth\"\n",
        "8. \"Laurie\"\n",
        "9. \"Hannah\"\n",
        "10. \"Jo\"\n",
        "\n",
        "<details>\n",
        "  <summary>Hint</summary>\n",
        "\n",
        "  When creating the following list, each token is put in quotations and followed with a comma.\n",
        "\n",
        "  The list will ultimately look like this:\n",
        "\n",
        "  ```\n",
        "  character_list = [\"Kate\", \"Kitty\", \"Amy\", \"Marmee\", \"John\", \"Minnie\", \"Beth\", \"Laurie\", \"Hannah\", \"Jo\"]\n",
        "  ```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8_I77BIcZWwo"
      },
      "outputs": [],
      "source": [
        "character_list = [\"Kate\", \"Kitty\", \"\",...]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KLPe1opYxruv"
      },
      "source": [
        "Now that you created the list, look at the numbers for our 3 remaining main characters. Who where they again?\n",
        "\n",
        "<details>\n",
        "  <summary>Hint</summary>\n",
        "\n",
        "  Look at the first block ðŸ˜€ (Remember the order!)\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "3jncFEDMctLJ"
      },
      "outputs": [],
      "source": [
        "print(\"character\", \" \", \"frequency in text\", \"\\n\")\n",
        "for character in character_list:\n",
        "  print(character, \" \", word_count[character])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
